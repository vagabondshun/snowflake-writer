# RAGç³»ç»Ÿè‡ªå®šä¹‰æŒ‡å—

## ğŸ“ æ•°æ®åº“å­˜å‚¨ä½ç½®

### é»˜è®¤å­˜å‚¨ç»“æ„

```
snowflake_projects/my_novel/
â”œâ”€â”€ .chroma/                    # ChromaDBå‘é‡æ•°æ®åº“
â”‚   â”œâ”€â”€ chroma.sqlite3         # SQLiteç´¢å¼•
â”‚   â”œâ”€â”€ [UUID]/                # å‘é‡æ•°æ®åˆ†ç‰‡
â”‚   â””â”€â”€ ...
â”œâ”€â”€ style_references/
â”‚   â””â”€â”€ metadata.json           # å‚è€ƒå°è¯´å…ƒæ•°æ®
â””â”€â”€ [å…¶ä»–é¡¹ç›®æ–‡ä»¶]
```

**å­˜å‚¨ä½ç½®**ï¼š
- **ChromaDB**: `é¡¹ç›®ç›®å½•/.chroma/`
- **å…ƒæ•°æ®**: `é¡¹ç›®ç›®å½•/style_references/metadata.json`
- **æ¯ä¸ªé¡¹ç›®ç‹¬ç«‹å­˜å‚¨**ï¼Œäº’ä¸å¹²æ‰°

### æ•°æ®åº“æ¥æº

1. **è‡ªåŠ¨åˆ›å»º**: é¦–æ¬¡è°ƒç”¨`enable_style_rag()`æ—¶è‡ªåŠ¨åˆ›å»º
2. **æŒä¹…åŒ–å­˜å‚¨**: æ•°æ®ä¿å­˜åœ¨æœ¬åœ°ç£ç›˜ï¼Œé‡å¯åä»å¯ç”¨
3. **é¡¹ç›®éš”ç¦»**: æ¯ä¸ªå°è¯´é¡¹ç›®æœ‰ç‹¬ç«‹çš„æ•°æ®åº“

---

## ğŸ¨ è‡ªå®šä¹‰é€‰é¡¹

### 1. è‡ªå®šä¹‰Embeddingæ¨¡å‹

å½“å‰ä½¿ç”¨çš„æ˜¯ `paraphrase-MiniLM-L6-v2`ï¼ˆè‹±æ–‡ä¼˜åŒ–ï¼Œ90MBï¼‰

**æ›´æ¢ä¸ºå…¶ä»–æ¨¡å‹**ï¼š

ç¼–è¾‘ `style_rag.py` ç¬¬89è¡Œï¼š

```python
# é»˜è®¤ï¼ˆè‹±æ–‡ä¼˜åŒ–ï¼‰
self.model = SentenceTransformer('paraphrase-MiniLM-L6-v2')

# æ›´æ¢ä¸ºå¤šè¯­è¨€æ¨¡å‹ï¼ˆä¸­æ–‡æ•ˆæœæ›´å¥½ï¼‰
self.model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')

# æ›´æ¢ä¸ºä¸­æ–‡ä¸“ç”¨æ¨¡å‹
self.model = SentenceTransformer('shibing624/text2vec-base-chinese')

# ä½¿ç”¨æ›´å¤§çš„æ¨¡å‹ï¼ˆæ•ˆæœæ›´å¥½ä½†æ›´æ…¢ï¼‰
self.model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')
```

**æ¨èæ¨¡å‹å¯¹æ¯”**ï¼š

| æ¨¡å‹ | è¯­è¨€ | å¤§å° | é€Ÿåº¦ | è´¨é‡ | æ¨èåº¦ |
|------|-----|------|------|------|-------|
| `paraphrase-MiniLM-L6-v2` | è‹±æ–‡ | 90MB | å¿« | ä¸­ | â­â­â­ |
| `paraphrase-multilingual-MiniLM-L12-v2` | å¤šè¯­è¨€ | 470MB | ä¸­ | é«˜ | â­â­â­â­â­ |
| `shibing624/text2vec-base-chinese` | ä¸­æ–‡ | 400MB | ä¸­ | é«˜ | â­â­â­â­â­ |
| `all-mpnet-base-v2` | è‹±æ–‡ | 420MB | æ…¢ | å¾ˆé«˜ | â­â­â­â­ |

**å¦‚ä½•æ›´æ¢æ¨¡å‹**ï¼š

```python
# æ–¹æ³•1: ä¿®æ”¹æºç ï¼ˆæ°¸ä¹…ç”Ÿæ•ˆï¼‰
# ç¼–è¾‘ style_rag.py ç¬¬89è¡Œ

# æ–¹æ³•2: ç»§æ‰¿å¹¶è¦†ç›–ï¼ˆä¸ä¿®æ”¹æºç ï¼‰
from style_rag import StyleRAG
from sentence_transformers import SentenceTransformer

class CustomStyleRAG(StyleRAG):
    def __init__(self, project_path):
        super().__init__(project_path)
        # è¦†ç›–æ¨¡å‹
        self.model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
```

---

### 2. è‡ªå®šä¹‰æ•°æ®åº“ä½ç½®

**é»˜è®¤è¡Œä¸º**ï¼šæ•°æ®åº“å­˜å‚¨åœ¨é¡¹ç›®ç›®å½•ä¸‹

**è‡ªå®šä¹‰è·¯å¾„**ï¼š

```python
# ä¿®æ”¹ style_rag.py ç¬¬75è¡Œ

# é»˜è®¤ï¼ˆé¡¹ç›®ç›®å½•ä¸‹ï¼‰
chroma_path = project_path / ".chroma"

# è‡ªå®šä¹‰ä¸ºå…¨å±€å…±äº«ä½ç½®
chroma_path = Path.home() / ".snowflake_rag_global" / project_path.name

# è‡ªå®šä¹‰ä¸ºå¤–éƒ¨é©±åŠ¨å™¨ï¼ˆå¤§å®¹é‡å­˜å‚¨ï¼‰
chroma_path = Path("D:/RAG_Storage") / project_path.name

# è‡ªå®šä¹‰ä¸ºå†…å­˜æ•°æ®åº“ï¼ˆé‡å¯åä¸¢å¤±ï¼Œé€‚åˆæµ‹è¯•ï¼‰
# æ³¨æ„ï¼šéœ€è¦æ”¹ç”¨ Client() è€Œé PersistentClient()
```

**å®ç°å…¨å±€å…±äº«æ•°æ®åº“**ï¼š

```python
# åœ¨ style_rag.py çš„ __init__ æ–¹æ³•ä¸­ä¿®æ”¹ï¼š

# å…¨å±€å…±äº«æ¨¡å¼ï¼ˆæ‰€æœ‰é¡¹ç›®å…±ç”¨åŒä¸€ä¸ªæ•°æ®åº“ï¼‰
self.global_mode = True  # æ–°å¢é…ç½®é¡¹

if self.global_mode:
    # å…¨å±€æ•°æ®åº“è·¯å¾„
    chroma_path = Path.home() / ".snowflake_rag_shared"
    collection_name = f"project_{project_path.name}"
else:
    # é¡¹ç›®ç‹¬ç«‹æ•°æ®åº“ï¼ˆé»˜è®¤ï¼‰
    chroma_path = project_path / ".chroma"
    collection_name = "style_references"

self.client = chromadb.PersistentClient(
    path=str(chroma_path),
    settings=Settings(anonymized_telemetry=False)
)

self.collection = self.client.get_or_create_collection(
    name=collection_name,
    metadata={"hnsw:space": "cosine"}
)
```

**ä¼˜ç¼ºç‚¹å¯¹æ¯”**ï¼š

| æ¨¡å¼ | ä¼˜ç‚¹ | ç¼ºç‚¹ | é€‚ç”¨åœºæ™¯ |
|------|-----|------|---------|
| **é¡¹ç›®ç‹¬ç«‹** | æ•°æ®éš”ç¦»ã€æ˜“ç®¡ç† | é‡å¤å­˜å‚¨ç›¸åŒå‚è€ƒ | é»˜è®¤æ¨è |
| **å…¨å±€å…±äº«** | èŠ‚çœç©ºé—´ã€å‚è€ƒå¤ç”¨ | å¤šé¡¹ç›®å†²çªé£é™© | å¤šé¡¹ç›®ä½¿ç”¨ç›¸åŒå‚è€ƒ |
| **å¤–éƒ¨é©±åŠ¨** | ä¸å Cç›˜ç©ºé—´ | éœ€è¦æ‰‹åŠ¨è·¯å¾„é…ç½® | å¤§é‡å‚è€ƒå°è¯´ |

---

### 3. è‡ªå®šä¹‰ç›¸ä¼¼åº¦ç®—æ³•

**é»˜è®¤ä½¿ç”¨**: ä½™å¼¦ç›¸ä¼¼åº¦ (`cosine`)

**æ›´æ¢ä¸ºå…¶ä»–ç®—æ³•**ï¼š

ç¼–è¾‘ `style_rag.py` ç¬¬84è¡Œï¼š

```python
# é»˜è®¤ï¼ˆä½™å¼¦ç›¸ä¼¼åº¦ï¼‰
metadata={"hnsw:space": "cosine"}

# æ›´æ¢ä¸ºæ¬§å‡ é‡Œå¾—è·ç¦»
metadata={"hnsw:space": "l2"}

# æ›´æ¢ä¸ºå†…ç§¯
metadata={"hnsw:space": "ip"}
```

**ç®—æ³•å¯¹æ¯”**ï¼š

| ç®—æ³• | ç‰¹ç‚¹ | é€‚ç”¨åœºæ™¯ |
|------|-----|---------|
| `cosine` | å…³æ³¨æ–¹å‘ç›¸ä¼¼æ€§ | **æ¨è**ï¼Œé€‚åˆæ–‡æœ¬è¯­ä¹‰ |
| `l2` | å…³æ³¨ç»å¯¹è·ç¦» | é•¿åº¦æ•æ„Ÿçš„åŒ¹é… |
| `ip` | å…³æ³¨å†…ç§¯å¤§å° | å‘é‡å·²å½’ä¸€åŒ–æ—¶ä½¿ç”¨ |

---

### 4. è‡ªå®šä¹‰åˆ†å—ç­–ç•¥

**é»˜è®¤é…ç½®**ï¼š
- å—å¤§å°ï¼š500å­—ç¬¦
- æœ€å¤§å—æ•°ï¼š100ä¸ª

**è‡ªå®šä¹‰åˆ†å—å‚æ•°**ï¼š

```python
from story_engine import get_engine

engine = get_engine()

# æ–¹æ³•1: è°ƒç”¨æ—¶æŒ‡å®š
result = engine.add_style_reference(
    title="å‚è€ƒå°è¯´",
    content=content,
    chunk_size=800,      # æ›´å¤§çš„å—ï¼ˆæ›´å¤šä¸Šä¸‹æ–‡ï¼‰
    max_chunks=200       # å…è®¸æ›´å¤šå—
)

# æ–¹æ³•2: ä¿®æ”¹é»˜è®¤å€¼ï¼ˆç¼–è¾‘style_rag.pyï¼‰
def add_reference_novel(
    self,
    title: str,
    content: str,
    author: str = None,
    chunk_size: int = 800,  # â† ä¿®æ”¹è¿™é‡Œ
    max_chunks: int = 200   # â† ä¿®æ”¹è¿™é‡Œ
):
```

**åˆ†å—å¤§å°å»ºè®®**ï¼š

| å—å¤§å° | é€‚ç”¨åœºæ™¯ | Tokenæ¶ˆè€— | ä¸Šä¸‹æ–‡å®Œæ•´æ€§ |
|--------|---------|-----------|-------------|
| 300å­—ç¬¦ | å¿«é€ŸåŒ¹é…ã€é™ä½æˆæœ¬ | ä½ | è¾ƒå·® |
| 500å­—ç¬¦ | **é»˜è®¤æ¨è** | ä¸­ | è‰¯å¥½ |
| 800å­—ç¬¦ | é•¿ç¯‡å™è¿°ã€å¤æ‚é£æ ¼ | é«˜ | ä¼˜ç§€ |
| 1000+å­—ç¬¦ | å­¦æœ¯å†™ä½œã€ç‰¹æ®Šéœ€æ±‚ | å¾ˆé«˜ | å¾ˆå¥½ |

---

### 5. è‡ªå®šä¹‰åœºæ™¯ç±»å‹åˆ†ç±»

**é»˜è®¤åˆ†ç±»é€»è¾‘** (style_rag.py ç¬¬120-136è¡Œ)ï¼š

```python
def _classify_chunk_type(self, text: str) -> str:
    """ç®€å•çš„å—ç±»å‹åˆ†ç±»"""
    dialogue_markers = text.count('"') + text.count('"') + text.count('"')
    dialogue_ratio = dialogue_markers / max(len(text), 1)

    action_verbs = ['è·‘', 'èµ°', 'æ‰“', 'è¸¢', 'è·³', 'å†²', 'æ‰‘', 'æŠ“', 'æ¨']
    action_count = sum(text.count(verb) for verb in action_verbs)

    if dialogue_ratio > 0.1:
        return 'dialogue'
    elif action_count > 3:
        return 'action'
    elif len(text) > 300:
        return 'description'
    else:
        return 'mixed'
```

**å¢å¼ºåˆ†ç±»é€»è¾‘**ï¼š

```python
def _classify_chunk_type(self, text: str) -> str:
    """å¢å¼ºçš„å—ç±»å‹åˆ†ç±»"""

    # 1. å¯¹è¯æ£€æµ‹ï¼ˆæ›´ç²¾ç¡®ï¼‰
    dialogue_patterns = ['"', '"', '"', 'ã€Œ', 'ã€', 'è¯´', 'é“', 'é—®', 'ç­”']
    dialogue_score = sum(text.count(p) for p in dialogue_patterns)
    dialogue_ratio = dialogue_score / max(len(text), 1)

    # 2. åŠ¨ä½œæ£€æµ‹ï¼ˆæ‰©å±•åŠ¨è¯åº“ï¼‰
    action_verbs = [
        'è·‘', 'èµ°', 'æ‰“', 'è¸¢', 'è·³', 'å†²', 'æ‰‘', 'æŠ“', 'æ¨', 'æ‹‰',
        'å‡»', 'åˆº', 'ç ', 'åŠˆ', 'æŒ¡', 'é—ª', 'èº²', 'è½¬', 'æ—‹', 'é£'
    ]
    action_count = sum(text.count(verb) for verb in action_verbs)

    # 3. å¿ƒç†æå†™æ£€æµ‹
    psychological_words = ['æƒ³', 'è§‰å¾—', 'æ„Ÿåˆ°', 'è®¤ä¸º', 'å¿ƒé‡Œ', 'æ€è€ƒ']
    psych_count = sum(text.count(word) for word in psychological_words)

    # 4. ç¯å¢ƒæå†™æ£€æµ‹
    environment_words = ['å¤©ç©º', 'é˜³å…‰', 'æ ‘æœ¨', 'æˆ¿é—´', 'è¡—é“', 'é£æ™¯']
    env_count = sum(text.count(word) for word in environment_words)

    # åˆ†ç±»å†³ç­–æ ‘
    if dialogue_ratio > 0.15:
        return 'dialogue'
    elif action_count > 5:
        return 'action'
    elif psych_count > 3:
        return 'psychological'  # æ–°å¢ç±»å‹
    elif env_count > 2:
        return 'environment'     # æ–°å¢ç±»å‹
    elif len(text) > 300:
        return 'narrative'
    else:
        return 'mixed'
```

**æ³¨æ„**: æ–°å¢ç±»å‹åï¼Œæ£€ç´¢æ—¶ä¹Ÿéœ€è¦ç›¸åº”è°ƒæ•´ `get_style_context()` çš„ `type_mapping`ã€‚

---

### 6. è‡ªå®šä¹‰æ£€ç´¢ç­–ç•¥

**é»˜è®¤è¡Œä¸º**: è¿”å›å‰Nä¸ªæœ€ç›¸ä¼¼çš„æ ·æœ¬

**è‡ªå®šä¹‰æ£€ç´¢é€»è¾‘**ï¼š

```python
# åœ¨ style_rag.py çš„ retrieve_style_samples æ–¹æ³•ä¸­è‡ªå®šä¹‰

def retrieve_style_samples(
    self,
    query: str,
    n_results: int = 3,
    chunk_type: Optional[str] = None,
    ref_id: Optional[str] = None,
    min_similarity: float = 0.7  # æ–°å¢ï¼šæœ€å°ç›¸ä¼¼åº¦é˜ˆå€¼
) -> List[Dict[str, Any]]:
    """æ£€ç´¢ç›¸ä¼¼çš„é£æ ¼æ ·æœ¬"""

    # æ ‡å‡†æ£€ç´¢
    results = self.collection.query(
        query_texts=[query],
        n_results=n_results * 2,  # å¤šæ£€ç´¢ä¸€äº›å€™é€‰
        where=where if where else None
    )

    # è¿‡æ»¤ä½ç›¸ä¼¼åº¦æ ·æœ¬
    filtered_samples = []
    for i in range(len(results["documents"][0])):
        similarity = 1 - results["distances"][0][i]  # è½¬æ¢ä¸ºç›¸ä¼¼åº¦

        if similarity >= min_similarity:
            filtered_samples.append({
                "text": results["documents"][0][i],
                "metadata": results["metadatas"][0][i],
                "distance": results["distances"][0][i],
                "similarity": similarity
            })

    # åªè¿”å›å‰n_resultsä¸ª
    return filtered_samples[:n_results]
```

**é«˜çº§æ£€ç´¢ç­–ç•¥**ï¼š

```python
# å¤šæ ·æ€§é‡‡æ ·ï¼ˆé¿å…è¿”å›è¿‡äºç›¸ä¼¼çš„æ ·æœ¬ï¼‰
def retrieve_diverse_samples(self, query: str, n_results: int = 3):
    """æ£€ç´¢å¤šæ ·åŒ–çš„æ ·æœ¬"""

    # 1. å…ˆæ£€ç´¢è¾ƒå¤šå€™é€‰
    candidates = self.collection.query(
        query_texts=[query],
        n_results=n_results * 5
    )

    # 2. å¤šæ ·æ€§è¿‡æ»¤ï¼ˆç®€å•å®ç°ï¼šæŒ‰å­—ç¬¦é•¿åº¦åˆ†ç»„ï¼‰
    short = []  # < 300å­—ç¬¦
    medium = []  # 300-600
    long = []   # > 600

    for i, text in enumerate(candidates["documents"][0]):
        length = len(text)
        sample = {
            "text": text,
            "metadata": candidates["metadatas"][0][i],
            "distance": candidates["distances"][0][i]
        }

        if length < 300:
            short.append(sample)
        elif length < 600:
            medium.append(sample)
        else:
            long.append(sample)

    # 3. å¹³è¡¡é€‰æ‹©
    results = []
    for group in [medium, short, long]:  # ä¼˜å…ˆä¸­ç­‰é•¿åº¦
        results.extend(group[:n_results - len(results)])
        if len(results) >= n_results:
            break

    return results[:n_results]
```

---

## ğŸ”§ é«˜çº§è‡ªå®šä¹‰æ¡ˆä¾‹

### æ¡ˆä¾‹1: ä½¿ç”¨ä¸­æ–‡ä¼˜åŒ–æ¨¡å‹

```python
# 1. ä¿®æ”¹ style_rag.py ç¬¬89è¡Œ
self.model = SentenceTransformer('shibing624/text2vec-base-chinese')

# 2. é¦–æ¬¡è¿è¡Œä¼šè‡ªåŠ¨ä¸‹è½½ä¸­æ–‡æ¨¡å‹ï¼ˆ400MBï¼‰

# 3. ä½¿ç”¨
add_style_reference("ä½™å-æ´»ç€", content, "ä½™å")
# ä¸­æ–‡è¯­ä¹‰ç†è§£æ›´å‡†ç¡®
```

### æ¡ˆä¾‹2: å…¨å±€å…±äº«å‚è€ƒåº“

```python
# ä¿®æ”¹ style_rag.py __init__ æ–¹æ³•

def __init__(self, project_path: Path, shared_mode: bool = False):
    self.project_path = project_path
    self.shared_mode = shared_mode

    if shared_mode:
        # æ‰€æœ‰é¡¹ç›®å…±äº«åŒä¸€ä¸ªæ•°æ®åº“
        chroma_path = Path.home() / ".snowflake_rag_global"
        collection_name = "shared_style_references"
    else:
        # é¡¹ç›®ç‹¬ç«‹
        chroma_path = project_path / ".chroma"
        collection_name = "style_references"

    # å…¶ä½™ä»£ç ä¸å˜...
```

### æ¡ˆä¾‹3: å¤–éƒ¨APIæ›¿ä»£Sentence Transformers

```python
# å¦‚æœæƒ³ç”¨OpenAI/Anthropicçš„embedding API

import requests

class APIStyleRAG(StyleRAG):
    def __init__(self, project_path: Path):
        super().__init__(project_path)
        self.api_key = "your_api_key"
        self.model = None  # ä¸ç”¨æœ¬åœ°æ¨¡å‹

    def _get_embedding(self, text: str):
        """è°ƒç”¨å¤–éƒ¨APIè·å–embedding"""
        response = requests.post(
            "https://api.openai.com/v1/embeddings",
            headers={"Authorization": f"Bearer {self.api_key}"},
            json={
                "input": text,
                "model": "text-embedding-3-small"
            }
        )
        return response.json()["data"][0]["embedding"]

    def add_reference_novel(self, title, content, ...):
        # ä¿®æ”¹ä¸ºä½¿ç”¨ self._get_embedding() è€Œé self.model.encode()
        ...
```

---

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. æ•°æ®åº“å¤§å°æ§åˆ¶

```python
# é™åˆ¶æ€»å—æ•°
max_total_chunks = 500  # å…¨å±€ä¸Šé™

# æ·»åŠ å‰æ£€æŸ¥
stats = engine.get_rag_statistics()
if stats['total_chunks'] >= max_total_chunks:
    # åˆ é™¤æ—§çš„å‚è€ƒæˆ–æç¤ºç”¨æˆ·
    pass
```

### 2. æ‰¹é‡æ“ä½œä¼˜åŒ–

```python
# æ‰¹é‡æ·»åŠ å‚è€ƒ
references = [
    ("å°è¯´1", content1, "ä½œè€…1"),
    ("å°è¯´2", content2, "ä½œè€…2"),
    ("å°è¯´3", content3, "ä½œè€…3"),
]

for title, content, author in references:
    add_style_reference(title, content, author)
```

### 3. ç¼“å­˜Embeddingç»“æœ

```python
# å¦‚æœåŒä¸€ä¸ªåœºæ™¯ä¼šå¤šæ¬¡æ£€ç´¢ï¼Œå¯ä»¥ç¼“å­˜embedding
from functools import lru_cache

@lru_cache(maxsize=100)
def get_cached_embedding(text: str):
    return model.encode([text])[0]
```

---

## ğŸš¨ æ³¨æ„äº‹é¡¹

1. **æ¨¡å‹æ›´æ¢**: æ›´æ¢embeddingæ¨¡å‹åï¼Œéœ€è¦é‡æ–°æ·»åŠ æ‰€æœ‰å‚è€ƒå°è¯´
2. **æ•°æ®åº“è¿ç§»**: æ›´æ”¹æ•°æ®åº“è·¯å¾„åï¼Œæ—§æ•°æ®ä¸ä¼šè‡ªåŠ¨è¿ç§»
3. **ç‰ˆæœ¬å…¼å®¹**: ChromaDBç‰ˆæœ¬å‡çº§å¯èƒ½å¯¼è‡´æ•°æ®ä¸å…¼å®¹
4. **éšç§ä¿æŠ¤**: è‡ªå®šä¹‰è·¯å¾„æ—¶æ³¨æ„ä¸è¦å°†æ•°æ®åº“æäº¤åˆ°ç‰ˆæœ¬æ§åˆ¶

---

## ğŸ“– å®Œæ•´ç¤ºä¾‹

```python
# è‡ªå®šä¹‰é…ç½®çš„å®Œæ•´æµç¨‹

# 1. ä¿®æ”¹ style_rag.pyï¼ˆå¯é€‰ï¼‰
# 2. åˆå§‹åŒ–é¡¹ç›®
from story_engine import *

init_project("æˆ‘çš„å°è¯´")

# 3. å¯ç”¨RAGå¹¶éªŒè¯
result = enable_style_rag()
print(f"æ•°æ®åº“ä½ç½®: {result}")

# 4. æ·»åŠ å‚è€ƒï¼ˆä½¿ç”¨è‡ªå®šä¹‰å‚æ•°ï¼‰
engine = get_engine()
result = engine.add_style_reference(
    title="å‚è€ƒå°è¯´",
    content=novel_content,
    author="ä½œè€…å",
    chunk_size=800,      # è‡ªå®šä¹‰å—å¤§å°
    max_chunks=150       # è‡ªå®šä¹‰æœ€å¤§å—æ•°
)

# 5. æ£€ç´¢æ—¶æŒ‡å®šå‚æ•°
samples = engine.get_style_context_for_scene(
    scene_description="åœºæ™¯æè¿°",
    scene_type="narrative",
    n_samples=5  # è‡ªå®šä¹‰æ ·æœ¬æ•°
)

# 6. æŸ¥çœ‹ç»Ÿè®¡
stats = engine.get_rag_statistics()
print(f"æ•°æ®åº“ç»Ÿè®¡: {stats}")
```

---

å¸Œæœ›è¿™ä»½è‡ªå®šä¹‰æŒ‡å—èƒ½å¸®åŠ©ä½ æ ¹æ®éœ€æ±‚è°ƒæ•´RAGç³»ç»Ÿï¼ğŸ¨
